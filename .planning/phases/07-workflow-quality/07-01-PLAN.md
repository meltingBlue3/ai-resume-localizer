---
phase: 07-workflow-quality
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - workflow/resume_extraction.yml
  - workflow/resume_translation.yml
autonomous: true
requirements:
  - WKFL-01
  - WKFL-02
  - WKFL-03

must_haves:
  truths:
    - "Extraction workflow LLM prompt explicitly forbids adding information not in source text"
    - "Extraction workflow has a code node that strips <think> tags from LLM output before JSON cleaning"
    - "Extraction workflow has a code node that sorts work_experience and education by start_date descending"
    - "Translation workflow uses a single LLM node instead of two separate translation + localization nodes"
    - "Translation prompt forbids adding marketing language, fabricated numbers, or content not in original"
    - "Translation prompt specifies です/ます体 with light 謙譲語 for motivation only"
  artifacts:
    - path: "workflow/resume_extraction.yml"
      provides: "Rewritten extraction workflow with CoT stripping, constrained prompt, sorting code node"
      contains: "<think>"
    - path: "workflow/resume_translation.yml"
      provides: "Rewritten translation workflow with merged single LLM node and constrained prompt"
  key_links:
    - from: "workflow/resume_extraction.yml"
      to: "Dify extraction workflow"
      via: "YML import into Dify Cloud"
      pattern: "strip.*think|CoT"
    - from: "workflow/resume_translation.yml"
      to: "Dify translation workflow"
      via: "YML import into Dify Cloud"
      pattern: "motivation|strengths|summary"
---

<objective>
Rewrite both Dify workflow YML files to produce clean, fact-faithful output.

Purpose: Current extraction prompt is too permissive ("准确提取所有关键信息") leading to content fabrication. Current translation uses 2 LLM nodes causing semantic drift and explicitly instructs LLM to add marketing language. This plan constrains both workflows per user decisions: fact certainty over expression quality (事実確定性優先于表達品質).

Output: Updated `workflow/resume_extraction.yml` and `workflow/resume_translation.yml` ready for Dify Cloud import.
</objective>

<execution_context>
@C:/Users/zhang/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/zhang/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-workflow-quality/07-CONTEXT.md
@workflow/resume_extraction.yml
@workflow/resume_translation.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite extraction workflow with CoT stripping, constrained prompt, and sorting code node</name>
  <files>workflow/resume_extraction.yml</files>
  <action>
Modify the extraction workflow YML. The workflow pipeline changes from:
  Start → LLM → Code(JSON clean) → End
to:
  Start → LLM → Code(CoT strip) → Code(JSON clean) → Code(sort by date) → End

**1. Rewrite LLM extraction prompt (node 1740000000002):**

Replace the system prompt entirely. The new prompt must:
- Frame the task as "extract ONLY what is explicitly written in the resume text" (not "准确提取所有关键信息")
- Add explicit constraint: "简历中未出现的信息必须填 null，绝对不可推测、补充或生成任何原文中不存在的内容"
- Dates: "日期严格按照原文记载输出。如果简历只写了'2020年'没有月份，则输出'2020'，不要补充月份。格式尽量为YYYY-MM，但不完整日期按原样输出"
- Ongoing jobs: "在职/至今/当前/空白结束日期统一输出为 null"
- Section classification: "根据内容判断属于 work_experience 还是 project_experience，不要仅依赖简历中的段落标题"
- Cross-section extraction: "如果在简历任意位置发现公认的资格证书（如CET-4、CET-6、JLPT等），即使不在'证书'段落下，也应提取到 certifications 中"
- Keep the same JSON output structure as current prompt
- Remove the instruction about reverse chronological sorting (sorting moves to code node per user decision)
- Add: "不要输出任何 markdown 代码块标记，不要输出解释文字，只输出纯 JSON"
- Add: "不要输出 <think> 或任何思考过程标记"

**2. Add CoT stripping code node (new node, insert between LLM and existing JSON clean node):**

Create a new code node with id '1740000000005' positioned between LLM (1740000000002) and JSON clean (1740000000003). The code:
```python
import re

def main(llm_text: str) -> dict:
    # Strip <think>...</think> blocks (including multiline)
    text = re.sub(r'<think>[\s\S]*?</think>', '', llm_text, flags=re.DOTALL)
    return {"result": text.strip()}
```

Update edges:
- LLM (1740000000002) → CoT strip (1740000000005)
- CoT strip (1740000000005) → JSON clean (1740000000003)
- Remove direct LLM → JSON clean edge

The JSON clean node (1740000000003) input variable_selector must now read from 1740000000005.result instead of 1740000000002.text.

**3. Add sorting code node (new node, insert between JSON clean and End):**

Create a new code node with id '1740000000006' positioned between JSON clean (1740000000003) and End (1740000000004). The code:
```python
import json

def main(json_str: str) -> dict:
    data = json.loads(json_str)

    def sort_key(entry):
        """Sort by start_date descending. Entries without dates go last."""
        sd = entry.get("start_date") or ""
        return sd

    for field in ("work_experience", "education", "project_experience"):
        items = data.get(field)
        if isinstance(items, list) and len(items) > 1:
            data[field] = sorted(items, key=sort_key, reverse=True)

    return {"result": json.dumps(data, ensure_ascii=False)}
```

Update edges:
- JSON clean (1740000000003) → Sort (1740000000006)
- Sort (1740000000006) → End (1740000000004)
- Remove direct JSON clean → End edge

End node (1740000000004) output variable_selector must now read from 1740000000006.result.

**4. Update node positions** to accommodate the 2 new nodes. Space them evenly left-to-right.

Ensure valid YAML throughout. The file is a Dify DSL export — preserve all metadata fields (app, dependencies, kind, version, workflow features).
  </action>
  <verify>
    Validate YAML syntax: `python -c "import yaml; yaml.safe_load(open('workflow/resume_extraction.yml'))"` succeeds.
    Verify node count is 6 (Start, LLM, CoT strip, JSON clean, Sort, End).
    Verify edge count is 5 (Start→LLM, LLM→CoT, CoT→JSON, JSON→Sort, Sort→End).
    Grep for "think" in LLM prompt text to confirm instruction exists.
    Grep for "推测" or "补充" in prompt to confirm anti-fabrication instruction exists.
  </verify>
  <done>
    Extraction workflow YML has: constrained prompt forbidding fabrication, CoT stripping code node, date sorting code node. Pipeline is Start → LLM → CoT strip → JSON clean → Sort → End.
  </done>
</task>

<task type="auto">
  <name>Task 2: Rewrite translation workflow with merged single LLM node and constrained prompt</name>
  <files>workflow/resume_translation.yml</files>
  <action>
Restructure the translation workflow pipeline from:
  Start → LLM(core translation) → Code(JSON clean 1) → LLM(localization) → Code(JSON clean 2) → End
to:
  Start → LLM(merged translation) → Code(CoT strip) → Code(JSON clean) → End

**1. Remove the localization LLM node (1740100000003) and its JSON clean node (1740100000004).**

**2. Rewrite the core translation LLM node (1740100000002) prompt** to be a single merged translation+localization pass. The new system prompt must:

- Keep the CnResumeData → JpResumeData structure mapping (same input/output JSON structure)
- Translation rules (rewrite these per user decisions):
  - "原文に書かれていない事実、数字、経験を追加してはいけません。翻訳は原文の内容のみに基づくこと"
  - "「貢献」「成長」「チームワーク」などのマーケティング的表現を追加しないこと。原文にない概念は翻訳に含めない"
  - "文の再構成は許可するが、内容の追加は禁止。日本のビジネス文書の文体に合わせて文構造を調整してよい"
  - "数値は文脈から推論可能な場合のみ許可（例：日付範囲から算出した年数）。定量データの捏造は禁止"
- Keigo rules:
  - "文体: です/ます体を全体で使用"
  - "motivation セクションのみ軽い謙譲語を使用（「〜させていただきたい」等）。過度に堅い表現は避ける"
- Keep these from the current localization prompt (but constrained):
  - Katakana name generation (name_katakana from Chinese name)
  - Degree mapping (专科→短期大学卒業, 本科→学士, 硕士→修士, 博士→博士)
  - Certification name localization (translate to Japanese-recognized names)
  - Skill categorization
- Remove ALL of these problematic instructions from the old localization prompt:
  - "曖昧な表現は具体的なビジネス用語に置き換える" (encourages content addition)
  - "具体的なエピソードや数値を含む自己PRにする" (asks LLM to add episodes/numbers)
  - "「貢献」「成長」「チームワーク」を織り交ぜた志望動機にする" (adds marketing language)
  - "経験年数・専門分野・強みを端的にまとめる" for summary (implies generation beyond source)
- summary: "self_introduction の内容を日本語に翻訳する。原文にない情報を追加しない"
- motivation: "career_objective の内容を日本語に翻訳する。原文にない情報を追加しない"
- strengths: "self_introduction と skills の内容に基づいて日本語に翻訳する。原文にない情報を追加しない"
- project_experience → work_history mapping: keep this behavior
- Add: "JSON オブジェクトのみ出力。<think> タグや思考過程、markdown 記法は一切出力しない"

**3. Repurpose the existing first JSON clean code node (17715808726430) as a CoT stripping node:**

Replace its code with:
```python
import re

def main(llm_text: str) -> dict:
    text = re.sub(r'<think>[\s\S]*?</think>', '', llm_text, flags=re.DOTALL)
    return {"result": text.strip()}
```
Update its title to "CoT ストリップ" and description accordingly.

**4. Keep the original Code(JSON clean) node from the core translation path** or repurpose one of the two existing JSON clean nodes. The final JSON clean node reads from CoT strip output and produces the final result.

**5. Update edges to form:** Start(1740100000001) → LLM(1740100000002) → CoT strip(17715808726430) → JSON clean(remaining code node) → End(1740100000005)

**6. Remove stale nodes and edges** for the deleted localization LLM and its JSON clean node. Update End node output variable_selector to point to the final JSON clean node's result.

**7. Update node positions** to be evenly spaced for 4 remaining nodes (Start, LLM, CoT strip, JSON clean, End = 5 nodes total).

Ensure valid YAML throughout.
  </action>
  <verify>
    Validate YAML syntax: `python -c "import yaml; yaml.safe_load(open('workflow/resume_translation.yml'))"` succeeds.
    Verify only 1 LLM node exists (not 2).
    Verify node count is 5 (Start, LLM, CoT strip, JSON clean, End).
    Grep for "追加してはいけません" to confirm anti-fabrication instruction.
    Grep for "貢献.*成長.*チームワーク" does NOT appear as an instruction to add these (only as instruction NOT to add).
  </verify>
  <done>
    Translation workflow has single merged LLM node with constrained prompt. No marketing additions, no content fabrication instructions. Pipeline: Start → LLM → CoT strip → JSON clean → End. Localization behaviors (katakana, degree mapping, keigo) are integrated into the single LLM prompt without the problematic content-addition instructions.
  </done>
</task>

</tasks>

<verification>
1. Both YML files parse as valid YAML
2. Extraction workflow has 6 nodes with CoT strip and sort code nodes
3. Translation workflow has 5 nodes with single LLM node
4. No prompt text instructs the LLM to add content not in the original resume
5. CoT stripping code nodes exist in both workflows
6. Both workflows still output the same variable names (structured_resume, jp_resume_json) for backend compatibility
</verification>

<success_criteria>
- Extraction YML: constrained prompt + CoT stripping + date sorting code node
- Translation YML: merged single LLM node + constrained prompt + CoT stripping
- Both files are valid YAML importable to Dify Cloud
- Backend DifyClient.extract_resume() and DifyClient.translate_resume() can consume output without changes (same output variable names)
</success_criteria>

<output>
After completion, create `.planning/phases/07-workflow-quality/07-01-SUMMARY.md`
</output>
