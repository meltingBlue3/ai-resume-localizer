---
phase: 02-upload-extraction
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/models/__init__.py
  - backend/app/models/resume.py
  - backend/app/models/api.py
  - backend/app/config.py
  - backend/app/services/text_extractor.py
  - backend/app/services/dify_client.py
  - backend/app/api/__init__.py
  - backend/app/api/router.py
  - backend/app/api/routes/__init__.py
  - backend/app/api/routes/upload.py
  - backend/app/main.py
  - backend/requirements.txt
  - backend/.env.example
  - frontend/src/types/resume.ts
autonomous: true
user_setup:
  - service: dify-cloud
    why: "AI-powered resume extraction workflow"
    env_vars:
      - name: DIFY_BASE_URL
        source: "Dify Cloud dashboard — default https://api.dify.ai/v1"
      - name: DIFY_EXTRACTION_API_KEY
        source: "Dify Cloud → Studio → Your extraction workflow → API Access → API Key"
    dashboard_config:
      - task: "Create extraction workflow with resume_text string input and structured_resume JSON output"
        location: "Dify Cloud → Studio → Create Workflow"

must_haves:
  truths:
    - "Backend accepts PDF file upload and returns structured Chinese resume JSON"
    - "Backend accepts DOCX file upload and returns structured Chinese resume JSON"
    - "Text extraction produces non-empty output for valid PDF and DOCX files with Chinese text"
    - "Dify workflow receives extracted text and returns JSON conforming to CnResumeData schema"
    - "Missing fields in the extracted resume are represented as null, not hallucinated"
  artifacts:
    - path: "backend/app/models/resume.py"
      provides: "CnResumeData Pydantic model with all-nullable fields"
      contains: "class CnResumeData"
    - path: "backend/app/services/text_extractor.py"
      provides: "PDF and DOCX text extraction"
      exports: ["extract_text_from_pdf", "extract_text_from_docx"]
    - path: "backend/app/services/dify_client.py"
      provides: "Dify workflow API wrapper with timeout handling"
      contains: "class DifyClient"
    - path: "backend/app/api/routes/upload.py"
      provides: "POST /api/upload-and-extract endpoint"
      contains: "upload_and_extract"
    - path: "frontend/src/types/resume.ts"
      provides: "TypeScript interfaces mirroring Pydantic models"
      contains: "CnResumeData"
    - path: "backend/app/config.py"
      provides: "Settings with Dify env var loading via pydantic-settings"
      contains: "dify_extraction_api_key"
  key_links:
    - from: "backend/app/api/routes/upload.py"
      to: "backend/app/services/text_extractor.py"
      via: "extract_text_from_pdf / extract_text_from_docx call"
      pattern: "extract_text_from_(pdf|docx)"
    - from: "backend/app/api/routes/upload.py"
      to: "backend/app/services/dify_client.py"
      via: "DifyClient.extract_resume() call"
      pattern: "dify.*extract_resume"
    - from: "backend/app/main.py"
      to: "backend/app/api/router.py"
      via: "app.include_router()"
      pattern: "include_router"
---

<objective>
Build the complete backend pipeline for resume file upload and AI extraction: Pydantic data models, TypeScript type mirrors, text extraction services (PyMuPDF for PDF, python-docx for DOCX), Dify workflow client, and the POST /api/upload-and-extract endpoint.

Purpose: Establish the data contract (Pydantic + TypeScript) and backend services that the frontend upload and review UIs will consume. This is the foundation all other Phase 2 plans depend on.
Output: Working upload endpoint that accepts a PDF/DOCX file and returns raw_text + structured CnResumeData JSON via Dify extraction.
</objective>

<execution_context>
@C:/Users/zhang/.config/opencode/get-shit-done/workflows/execute-plan.md
@C:/Users/zhang/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-upload-extraction/02-RESEARCH.md

@backend/app/main.py
@backend/app/config.py
@backend/app/services/pdf_generator.py
@backend/requirements.txt
@backend/.env.example
@frontend/src/types/
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create data models, TypeScript types & expand config</name>
  <files>
    backend/app/models/__init__.py
    backend/app/models/resume.py
    backend/app/models/api.py
    backend/app/config.py
    backend/requirements.txt
    backend/.env.example
    frontend/src/types/resume.ts
  </files>
  <action>
    **1. Install pydantic-settings:** Add `pydantic-settings==2.9.1` to requirements.txt and run `pip install pydantic-settings`.

    **2. Create backend/app/models/__init__.py** (empty package marker).

    **3. Create backend/app/models/resume.py** with Pydantic models:
    - `EducationEntry(BaseModel)`: school, major, degree, start_date, end_date — all `str | None = None`
    - `WorkEntry(BaseModel)`: company, position, department, start_date, end_date, description — all `str | None = None`
    - `SkillEntry(BaseModel)`: name, level — all `str | None = None`
    - `CertificationEntry(BaseModel)`: name, date — all `str | None = None`
    - `CnResumeData(BaseModel)`: Personal (name, phone, email, date_of_birth, address, nationality, gender), Professional (education: `list[EducationEntry] | None`, work_experience: `list[WorkEntry] | None`, skills: `list[SkillEntry] | None`, certifications: `list[CertificationEntry] | None`, languages: `list[str] | None`), Content (self_introduction, career_objective, project_experience: `list[WorkEntry] | None`, awards: `list[str] | None`, hobbies) — all nullable with `None` defaults per EXTR-03.

    **4. Create backend/app/models/api.py** with API response model:
    - `UploadAndExtractResponse(BaseModel)`: raw_text: str, cn_resume_data: CnResumeData

    **5. Expand backend/app/config.py:**
    - Replace simple Path constants with a pydantic-settings `Settings(BaseSettings)` class.
    - Fields: `dify_base_url: str = "https://api.dify.ai/v1"`, `dify_extraction_api_key: str = ""`.
    - Computed properties for `base_dir`, `fonts_dir`, `templates_dir` preserving existing Path behavior.
    - `model_config = SettingsConfigDict(env_file=".env")`.
    - Export a singleton `settings = Settings()`.
    - IMPORTANT: Update any existing imports of `BASE_DIR`, `FONTS_DIR`, `TEMPLATES_DIR` in pdf_generator.py to use `settings.base_dir` etc. Check that the existing test-pdf endpoint still works after config refactor.

    **6. Update backend/.env.example** adding `DIFY_BASE_URL=https://api.dify.ai/v1` and `DIFY_EXTRACTION_API_KEY=app-your-key-here`.

    **7. Create frontend/src/types/resume.ts** with TypeScript interfaces mirroring the Pydantic models exactly:
    - `EducationEntry`, `WorkEntry`, `SkillEntry`, `CertificationEntry`, `CnResumeData` — all fields use `string | null` and `T[] | null` matching Python's nullable pattern.
    - Also export `UploadAndExtractResponse` interface: `{ raw_text: string; cn_resume_data: CnResumeData }`.
  </action>
  <verify>
    Run from backend/: `python -c "from app.models.resume import CnResumeData; print(CnResumeData.model_json_schema())"` — should print JSON schema with all nullable fields.
    Run from backend/: `python -c "from app.config import settings; print(settings.dify_base_url)"` — should print the Dify URL.
    Run `npm run build` from frontend/ — TypeScript compilation should succeed with new types file.
  </verify>
  <done>CnResumeData Pydantic model exists with all fields nullable, TypeScript interfaces mirror it exactly, config loads Dify env vars via pydantic-settings, existing PDF generation still works.</done>
</task>

<task type="auto">
  <name>Task 2: Text extraction services, Dify client & upload endpoint</name>
  <files>
    backend/app/services/text_extractor.py
    backend/app/services/dify_client.py
    backend/app/api/__init__.py
    backend/app/api/router.py
    backend/app/api/routes/__init__.py
    backend/app/api/routes/upload.py
    backend/app/main.py
    backend/requirements.txt
  </files>
  <action>
    **1. Install backend dependencies:** Add `PyMuPDF==1.27.1`, `python-docx==1.1.2`, `httpx==0.28.1` to requirements.txt and run `pip install PyMuPDF python-docx httpx`.

    **2. Create backend/app/services/text_extractor.py:**
    - `extract_text_from_pdf(content: bytes) -> str`: Open with `pymupdf.open(stream=content, filetype="pdf")`. Iterate pages, call `page.get_text("text", sort=True)` for reading-order extraction. Join pages with `"\n\n"`. Close doc after extraction.
    - `extract_text_from_docx(content: bytes) -> str`: Open with `Document(io.BytesIO(content))`. Iterate BOTH `doc.paragraphs` AND `doc.tables` (Pitfall 4 — Chinese resumes heavily use table layouts). For tables, join cell text with ` | ` per row. Join all parts with `"\n"`.
    - Use `import pymupdf` (not `import fitz` — modern convention for PyMuPDF 1.27.x).

    **3. Create backend/app/services/dify_client.py:**
    - `DifyWorkflowError(Exception)` custom exception.
    - `DifyClient` class with `__init__(self, api_key: str, base_url: str)`. Creates `httpx.AsyncClient` with `timeout=httpx.Timeout(90.0, connect=10.0)` (Pitfall 3 — Cloudflare 100s limit).
    - `async extract_resume(self, resume_text: str, user: str = "default") -> dict`: POST to `/workflows/run` with `{"inputs": {"resume_text": resume_text}, "response_mode": "blocking", "user": user}` and Bearer token auth. Check `data.status == "succeeded"`, raise DifyWorkflowError if not. Parse `outputs.structured_resume` — handle both str (JSON.loads) and dict cases. Return parsed dict.
    - `async close(self)`: Call `self._http.aclose()`.

    **4. Create route modules:**
    - `backend/app/api/__init__.py` (empty package marker).
    - `backend/app/api/routes/__init__.py` (empty package marker).
    - `backend/app/api/routes/upload.py`: Define `router = APIRouter()`. Endpoint `POST /api/upload-and-extract` accepts `file: UploadFile`. Validate `file.content_type` against allowed MIME types (`application/pdf`, `application/vnd.openxmlformats-officedocument.wordprocessingml.document`). Read content once with `await file.read()` (Pitfall 7). Reject if >10MB. Extract text via appropriate extractor. Reject with 422 if extracted text is empty (scanned PDF case). Create DifyClient from settings, call `extract_resume(raw_text)`, validate response against CnResumeData model, return `UploadAndExtractResponse`. Wrap Dify call in try/except for DifyWorkflowError and httpx errors, returning appropriate HTTP error codes.
    - `backend/app/api/router.py`: Create `api_router = APIRouter()`, include upload router.

    **5. Update backend/app/main.py:**
    - Import and include `api_router` from `app.api.router`.
    - Keep existing `/api/health` and `/api/test-pdf/{template_name}` endpoints.
    - The upload route is registered via the included router.
  </action>
  <verify>
    Run from backend/: `python -c "from app.services.text_extractor import extract_text_from_pdf, extract_text_from_docx; print('Extractors OK')"`.
    Run from backend/: `python -c "from app.services.dify_client import DifyClient; print('DifyClient OK')"`.
    Start the server with `uvicorn app.main:app --reload` and verify `GET /api/health` still returns `{"status": "ok"}`.
    Verify OpenAPI docs at `http://localhost:8000/docs` shows the new `POST /api/upload-and-extract` endpoint.
  </verify>
  <done>POST /api/upload-and-extract endpoint is registered and visible in OpenAPI docs. Text extractors import cleanly. DifyClient imports cleanly. Existing /api/health and /api/test-pdf endpoints still work.</done>
</task>

</tasks>

<verification>
- `python -c "from app.models.resume import CnResumeData; m = CnResumeData(); print(m.model_dump())"` — all fields None
- `python -c "from app.config import settings; print(settings.fonts_dir)"` — prints correct path
- `uvicorn app.main:app` starts without errors
- `/docs` shows POST /api/upload-and-extract with file parameter
- `/api/health` returns 200
- `/api/test-pdf/rirekisho` still returns PDF (config refactor didn't break existing code)
- `npm run build` in frontend/ succeeds (TypeScript types compile)
</verification>

<success_criteria>
Backend pipeline fully wired: file upload → text extraction → Dify API call → structured JSON response. Data contract established in both Python (Pydantic) and TypeScript. Config loads Dify env vars. All existing endpoints preserved.
</success_criteria>

<output>
After completion, create `.planning/phases/02-upload-extraction/02-01-SUMMARY.md`
</output>
